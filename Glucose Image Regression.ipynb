{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9866e740",
   "metadata": {},
   "source": [
    "# 0 - Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bf267",
   "metadata": {},
   "source": [
    "<p> \n",
    "Prior to creating this notebook and developing the code, I went through our current dataset and I compiled all of the folders of images (named according to the person) into one folder. Inside of that folder, I renamed all of the folders with images to measured glucose value of the corresponding person. This process resulted in a folder containing several other folders with glucose values as names of the folders and the folders containing images with those same glucose values. \n",
    "</p>\n",
    "<p>\n",
    "Also removed many \"bad\" images from the datasets; these images were ones that were captured incorrectly. Furthermore, many of the images in the second image capture were renamed to random numbers to allow for the file-folders to be merged into one single folder with subdirectories described above.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd6c19d",
   "metadata": {},
   "source": [
    "# 1 - Importing Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd0938f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Python Libraries\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba49a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c004c",
   "metadata": {},
   "source": [
    "# 2 - Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c03828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kazi\\AppData\\Local\\Temp\\ipykernel_4256\\2828338069.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "#Initializing Print Settings for Dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5583f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\\Machine Learning\\Glucose Estimation\\data_second\n"
     ]
    }
   ],
   "source": [
    "#Getting the Directory of this Notebook for Later Use\n",
    "directory = os.getcwd() + '\\data_second'\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9d8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Series for Image-Filepaths and Glucose Values\n",
    "\n",
    "#Creating list with all image filepaths and one for glucose values.\n",
    "files = glob.glob(directory + '\\**\\*')\n",
    "values = [None] * len(files)\n",
    "\n",
    "#Correcting all filepaths and adding their respective values to the other list. \n",
    "x = 0\n",
    "while x < len(files):\n",
    "    files[x] = files[x].replace('\\\\','/')\n",
    "    str = files[x][51:]\n",
    "    values[x] = int(str[0:str.index('/')])\n",
    "    x = x + 1\n",
    "\n",
    "#Converting lists into Panda Series for creating a Dataframe\n",
    "files = pd.Series(files, name='Filepath')\n",
    "values = pd.Series(values, name='Glucose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb816083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/100/image0 (2).jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/100/image0 (3).jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/100/image0.jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/100/image1 (2).jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/100/image1 (3).jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/99/image5.jpg</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/99/image6.jpg</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/99/image7.jpg</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/99/image8.jpg</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/99/image9.jpg</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Filepath  Glucose\n",
       "0     X:/Machine Learning/Glucose Estimation/data_second/100/image0 (2).jpg  100    \n",
       "1     X:/Machine Learning/Glucose Estimation/data_second/100/image0 (3).jpg  100    \n",
       "2     X:/Machine Learning/Glucose Estimation/data_second/100/image0.jpg      100    \n",
       "3     X:/Machine Learning/Glucose Estimation/data_second/100/image1 (2).jpg  100    \n",
       "4     X:/Machine Learning/Glucose Estimation/data_second/100/image1 (3).jpg  100    \n",
       "...                                                                     ...  ...    \n",
       "1151  X:/Machine Learning/Glucose Estimation/data_second/99/image5.jpg       99     \n",
       "1152  X:/Machine Learning/Glucose Estimation/data_second/99/image6.jpg       99     \n",
       "1153  X:/Machine Learning/Glucose Estimation/data_second/99/image7.jpg       99     \n",
       "1154  X:/Machine Learning/Glucose Estimation/data_second/99/image8.jpg       99     \n",
       "1155  X:/Machine Learning/Glucose Estimation/data_second/99/image9.jpg       99     \n",
       "\n",
       "[1156 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining the Series into a Dataframe\n",
    "images = pd.concat([files, values], axis=1)\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850a8eb",
   "metadata": {},
   "source": [
    "# 3 - Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0d7782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/84/image5.jpg</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/101/524356.jpg</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/95/image2.jpg</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/85/image13 (2).jpg</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/84/image13 (2).jpg</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/91/image13 (2).jpg</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/110/image12.jpg</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/140/image6.jpg</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/147/342.jpg</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/108/image6.jpg</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Filepath  Glucose\n",
       "0     X:/Machine Learning/Glucose Estimation/data_second/84/image5.jpg       84     \n",
       "1     X:/Machine Learning/Glucose Estimation/data_second/101/524356.jpg      101    \n",
       "2     X:/Machine Learning/Glucose Estimation/data_second/95/image2.jpg       95     \n",
       "3     X:/Machine Learning/Glucose Estimation/data_second/85/image13 (2).jpg  85     \n",
       "4     X:/Machine Learning/Glucose Estimation/data_second/84/image13 (2).jpg  84     \n",
       "...                                                                     ...  ..     \n",
       "1151  X:/Machine Learning/Glucose Estimation/data_second/91/image13 (2).jpg  91     \n",
       "1152  X:/Machine Learning/Glucose Estimation/data_second/110/image12.jpg     110    \n",
       "1153  X:/Machine Learning/Glucose Estimation/data_second/140/image6.jpg      140    \n",
       "1154  X:/Machine Learning/Glucose Estimation/data_second/147/342.jpg         147    \n",
       "1155  X:/Machine Learning/Glucose Estimation/data_second/108/image6.jpg      108    \n",
       "\n",
       "[1156 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffling the Dataset\n",
    "\n",
    "#Settings Random State for Replication and Resetting Indices for Ordering \n",
    "ds = images.sample(1156, random_state=7).reset_index(drop=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb95441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/112/image9.jpg</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/123/image10.jpg</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/95/image7 (2).jpg</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/105/image11.jpg</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/83/2.jpg</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/98/image6.jpg</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/79/image1.jpg</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/113/image9.jpg</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/109/image7.jpg</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>X:/Machine Learning/Glucose Estimation/data_second/84/image14.jpg</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>867 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 Filepath  Glucose\n",
       "0    X:/Machine Learning/Glucose Estimation/data_second/112/image9.jpg     112    \n",
       "1    X:/Machine Learning/Glucose Estimation/data_second/123/image10.jpg    123    \n",
       "2    X:/Machine Learning/Glucose Estimation/data_second/95/image7 (2).jpg  95     \n",
       "3    X:/Machine Learning/Glucose Estimation/data_second/105/image11.jpg    105    \n",
       "4    X:/Machine Learning/Glucose Estimation/data_second/83/2.jpg           83     \n",
       "..                                                           ...           ..     \n",
       "862  X:/Machine Learning/Glucose Estimation/data_second/98/image6.jpg      98     \n",
       "863  X:/Machine Learning/Glucose Estimation/data_second/79/image1.jpg      79     \n",
       "864  X:/Machine Learning/Glucose Estimation/data_second/113/image9.jpg     113    \n",
       "865  X:/Machine Learning/Glucose Estimation/data_second/109/image7.jpg     109    \n",
       "866  X:/Machine Learning/Glucose Estimation/data_second/84/image14.jpg     84     \n",
       "\n",
       "[867 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the Dataset\n",
    "\n",
    "#Chose higher test sample because the dataset size is small and reset indices again.\n",
    "train, test = train_test_split(ds, train_size=0.75, random_state = 7)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d49632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Image Processors for Normalizing Image Data\n",
    "\n",
    "#Scaling the pixel RGB values of each image down by 255 to make the RGB values 0-1.\n",
    "#This standardizes the data like how it would be done with numeric data.\n",
    "#This process makes the model train much more efficiently.\n",
    "\n",
    "#A validation set is created for testing model during training.\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.20\n",
    ")\n",
    "\n",
    "#A validation set is not needed for testing.\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4757242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 694 validated image filenames.\n",
      "Found 173 validated image filenames.\n",
      "Found 289 validated image filenames.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DataFrameIterator at 0x209b75b7130>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses the previous image generators to convert the images into tensors.\n",
    "#The tensors are numeric matrices containing the respective RGB values for each pixel.\n",
    "#The tensors have 3 dimensions: height, width, and RGB colors.\n",
    "#In our case those would be: 480, 640, and 3.\n",
    "\n",
    "\n",
    "#First the dataframe and it's columns are selected for creating the training data.\n",
    "#Setting target size to 160 x 120 rescales the images to a smaller size for speed/efficiency.\n",
    "#Setting class_mode to raw makes the generator disregard classes to make sure that the model is regression, not classification.\n",
    "#The batch size determines how many images are processed in a single iteration.\n",
    "#Using 32 as the batchsize helps the generator use less computing power.\n",
    "#We also shuffle the data again to make sure that the model gets a random sample of the data.\n",
    "#We set the random seed to make the generation replicable.\n",
    "\n",
    "#We first create the training subset for our model (the data used to train).\n",
    "train_data = train_generator.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    x_col='Filepath',\n",
    "    y_col='Glucose',\n",
    "    target_size=(120, 160),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    seed=7,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "#Then we create the validation subset for our model (the data used to test performance during training).\n",
    "val_data = train_generator.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    x_col='Filepath',\n",
    "    y_col='Glucose',\n",
    "    target_size=(120, 160),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    seed=7,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "#Finally we create the testing subset for our model (the data used to test performance after training).\n",
    "test_data = test_generator.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    x_col='Filepath',\n",
    "    y_col='Glucose',\n",
    "    target_size=(120, 160),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66266292",
   "metadata": {},
   "source": [
    "# 4 - Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90eadb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 120, 160, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 118, 158, 128)     3584      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 58, 78, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 76, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 27, 37, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 25, 35, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 12, 17, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 15, 512)       1180160   \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 14336)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14336)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                458784    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,085,313\n",
      "Trainable params: 2,085,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating the model for training.\n",
    "\n",
    "\n",
    "#The input layer fits the following layers to the dimensions of the tensors created by the generators.\n",
    "\n",
    "#Convolutional layers Slides a 3x3 window across the image to extract features in the form of shapes, corners, edges, etc.\n",
    "#The window is 3x3 because our image is small the window should be proportionate to the image size to detect small patterns.\n",
    "#It does this by taking the dot product of that sliding window and setting it to the middle pixel to create feature images.\n",
    "#The sliding window can overlap with previous slides but it cannot go outside of the image.\n",
    "#Different filters use different values (weights) in the windows to find different features: edges, shapes, and other patterns.\n",
    "#The number of filters starts low to detect bigger and more general features but increase to detect smaller features.\n",
    "#Because the window is 3x3 and it must not cover the outside of the image, a portion of the border of the image is lost.\n",
    "\n",
    "#Max Pool layers downscale the image tensors by taking the maximum of a certain area of an image.\n",
    "#This downscaling helps by making the tensors easier to process, which is needed because more filters are used.\n",
    "\n",
    "#Flatten layers take all of the features extracted from the image and puts them on a single plane.\n",
    "\n",
    "#Dense layers are just normal neural perceptrons that try to train to the data and find patterns within the features.\n",
    "\n",
    "#Dropout layers randomly remove a percentage of the previous layer's output to reduce overfitting.\n",
    "\n",
    "#Then the output layer takes the cumalation of the patterns in the Dense layers to output a singular linear value (Glucose).\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(120, 160, 3))\n",
    "\n",
    "conv_1 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu') (inputs)\n",
    "maxp_1 = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=2) (conv_1)\n",
    "conv_2 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu') (maxp_1)\n",
    "maxp_2 = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=2) (conv_2)\n",
    "conv_3 = tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu') (maxp_2)\n",
    "maxp_3 = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=2) (conv_3)\n",
    "conv_4 = tf.keras.layers.Conv2D(512, kernel_size=3, activation='relu') (maxp_3)\n",
    "maxp_4 = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=2) (conv_4)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten() (maxp_4)\n",
    "\n",
    "dropout = tf.keras.layers.Dropout(0.2) (flatten)\n",
    "\n",
    "dense = tf.keras.layers.Dense(32, activation='relu') (dropout)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='relu') (dense)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "#Compiles the model using a standard optimizer and uses MSE for measuring performance.\n",
    "#MSE is the Mean-Square-Error the model calculates for glucose compared to the actual glucose values.\n",
    "#MSE is the mean of the squared deviations of the predicted values from the actual values.\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae' \n",
    ")\n",
    "\n",
    "#Summarizes the features of the models.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa6797f",
   "metadata": {},
   "source": [
    "# 5 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2261fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 35s 772ms/step - loss: 27.1770 - val_loss: 21.0781\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 31s 712ms/step - loss: 18.7222 - val_loss: 16.5901\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 31s 710ms/step - loss: 19.1671 - val_loss: 16.6540\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 31s 708ms/step - loss: 17.5453 - val_loss: 17.1972\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 35s 804ms/step - loss: 22.1890 - val_loss: 17.5394\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 20.2481 - val_loss: 17.0502\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 34s 780ms/step - loss: 18.9367 - val_loss: 16.5639\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 32s 723ms/step - loss: 17.1243 - val_loss: 20.4324\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 31s 707ms/step - loss: 17.5375 - val_loss: 22.3533\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 31s 703ms/step - loss: 17.8685 - val_loss: 22.1866\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 31s 710ms/step - loss: 18.8103 - val_loss: 17.3686\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 31s 710ms/step - loss: 17.1007 - val_loss: 19.7361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28c72e33a90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fits the model to training and validation data.\n",
    "\n",
    "\n",
    "#Uses 100 epochs as the number of training iterations the model goes through. \n",
    "#The EarlyStopping callback ensures that the model stops training after the validation loss stagnates for 5 iterations (epochs).\n",
    "#The callback then chooses the weights from the best epoch to save for the final model.\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=20,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc401c0",
   "metadata": {},
   "source": [
    "# 6 - Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "797492b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 5s 254ms/step\n"
     ]
    }
   ],
   "source": [
    "#Tests the model to the testing data.\n",
    "#Squeezes the output array into a single list.\n",
    "predicted_ages = np.squeeze(model.predict(test_data))\n",
    "true_ages = test_data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "556a0485",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93.61561  93.48403  93.693695 93.69176  93.93919  93.86616  93.65112\n",
      " 95.66552  93.89751  93.70199  92.12168  93.69805  93.79745  93.7727\n",
      " 93.64244  94.654106 93.56087  93.67007  93.55132  93.928185 93.791435\n",
      " 93.74569  93.68096  93.796425 93.53017  91.38709  93.61092  93.76403\n",
      " 93.40692  93.3911   96.65067  93.7335   93.701164 93.61939  93.72281\n",
      " 93.843506 93.59104  93.77111  93.824486 93.70745  93.7502   93.69912\n",
      " 93.79561  93.79061  93.86136  96.07127  95.62182  93.70385  93.842384\n",
      " 93.81794  90.208595 93.70859  93.63934  93.56605  93.52999  93.72033\n",
      " 97.26544  93.57     89.82853  93.75096  93.74264  89.40403  93.560265\n",
      " 93.70133  93.80825  93.71322  91.87025  93.574135 93.73759  93.46586\n",
      " 89.380875 93.67596  93.59968  93.54777  93.80938  93.52483  93.479515\n",
      " 93.78763  95.119804 93.68341  93.65716  93.71064  93.77108  94.814705\n",
      " 93.84886  93.452614 91.634346 93.59309  93.22383  93.60226  93.86582\n",
      " 93.42141  93.49784  93.69982  93.727005 93.14289  93.62435  93.56608\n",
      " 93.80085  93.66869  93.444695 94.34374  93.779564 92.220665 93.59953\n",
      " 93.776276 93.75332  94.11148  93.82422  93.736916 93.81719  93.639275\n",
      " 93.681244 93.5899   93.40556  93.65801  93.719765 93.81711  93.688805\n",
      " 96.10732  96.249695 93.599174 93.63619  93.4457   93.81786  93.73311\n",
      " 93.68598  93.32879  93.08701  93.77447  93.33491  93.61361  93.83997\n",
      " 93.399635 93.857216 93.72814  93.45266  93.59931  93.697334 94.04192\n",
      " 93.63617  93.91198  93.83538  93.65827  93.73232  96.20226  93.60317\n",
      " 97.26544  93.625145 93.686646 93.729546 93.50048  93.86095  92.93642\n",
      " 93.694115 93.72929  93.85279  93.59621  93.67666  93.44718  92.99382\n",
      " 93.67945  95.8929   93.73205  93.723045 92.77408  93.77268  93.67565\n",
      " 93.57816  93.70691  95.99508  93.60143  93.78976  93.68366  92.12168\n",
      " 93.55068  93.75437  93.70907  93.35308  93.52238  93.73089  93.5124\n",
      " 96.442825 93.88604  92.631966 93.70963  91.3021   93.5958   93.45292\n",
      " 95.60323  93.76335  93.825226 93.64692  93.691475 93.74319  93.477715\n",
      " 93.64454  93.63105  93.53924  93.59147  93.719376 93.76775  93.96118\n",
      " 93.477974 93.61039  93.600975 90.399666 93.78669  93.97006  93.61334\n",
      " 93.676895 93.56927  93.57434  93.486885 93.946785 93.780685 93.69323\n",
      " 93.46913  93.7344   94.81243  93.62408  89.84347  93.601166 93.85378\n",
      " 93.72144  96.10732  93.709816 96.715034 89.85932  93.504395 93.52676\n",
      " 93.505295 93.080055 93.61154  93.48709  89.01416  93.6548   95.927864\n",
      " 93.7418   93.70216  93.41031  93.83277  94.20281  93.83447  93.539085\n",
      " 89.78797  93.6847   93.674324 93.81239  93.3791   92.892746 93.858055\n",
      " 93.466225 93.68343  89.37     93.74717  93.69416  96.02198  93.73992\n",
      " 93.75944  95.373566 93.15501  93.65142  93.77979  93.59292  92.33594\n",
      " 93.58211  95.97463  93.626144 93.845406 93.520546 93.664536 93.80833\n",
      " 93.665276 96.13291  93.69465  93.69419  93.51235  93.67234  93.6932\n",
      " 93.68166  96.86851  93.61228  93.1482   93.72146  93.59193  93.64868\n",
      " 93.56394  93.69485 ]\n",
      "[ 99 113  83  85  92  94  95  92  91  78 147 101  91  87  84 111 120  95\n",
      " 123 113 100 120 101 113  92 147  83 124 100  85 110  84  83 102  87 103\n",
      " 122 124 124 131  92 134 116 112  94  92  83  85 124 134  97 122  71  95\n",
      " 124 124 110  75  97  87 127  97  75 106 106  79 147 135  71 188  97  80\n",
      " 108 104  98  87 123 113 111  98 106  79  86 111 140 124 147  99 109 120\n",
      "  94 140  94  82  91  83 113 100 127  83  77 142  80 147 124  98  79 142\n",
      "  84 113 140 103  98 100 109  85  86 120  85 110 106  85 127 113 127  92\n",
      "  84 142  83  85 100 124  96 188  80 116  92  87  77 111  83  99  98  91\n",
      "  71  95  95 110  80  80  91  80 100 101 103  91 100  94  80 131 101  82\n",
      "  95  95 122  86 124 104 134  87  92 113  78 142 147 188 122  84 124  84\n",
      " 103 109 110  84 147 142  97 188 135  92  95  94 188 122 103 112 124  78\n",
      "  87  85 134 100 142 101 124  84  97  84 131 124 101  99 104  95 112  80\n",
      "  83  79  91  83  75 135 124 113  99 110 100 110  97  95  87 142 109 122\n",
      " 101  97  98  83 102 127 140 100 131 134  85  97  92  78  95  77 101 124\n",
      " 113  79  97 124  77 110  85  91 131  95  75  71 116 147  75 131 112 140\n",
      "  96  95  83 105 106  87  98 102 127  98  95 110  87  83  83 135 123 104\n",
      "  87]\n"
     ]
    }
   ],
   "source": [
    "#Showing the different values that our model predicted compared to their actual counterparts.\n",
    "#Our model seems to overfit towards values between 100-105\n",
    "print(predicted_ages)\n",
    "print(true_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24026b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Average We Are 17.99 Off When Predicting Glucose\n"
     ]
    }
   ],
   "source": [
    "#Finds the Root of the MSE of the previous prediction.\n",
    "error = model.evaluate(test_data, verbose=0)\n",
    "print(\"On Average We Are {:.2f} Off When Predicting Glucose\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea26c8f",
   "metadata": {},
   "source": [
    "# 7 - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bac09062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 120, 160, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 120, 160, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 120, 160, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 60, 80, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 60, 80, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 60, 80, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 30, 40, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 30, 40, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 30, 40, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 30, 40, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 15, 20, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 15, 20, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 15, 20, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 15, 20, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 7, 10, 512)        0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 7, 10, 512)        2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 7, 10, 512)        2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 7, 10, 512)        2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 3, 5, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7680)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               983168    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,708,225\n",
      "Trainable params: 993,537\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create a Transfer Learning Model\n",
    "\n",
    "#Transfer learning is the process of using a previously setup/trained model, changing the inputs, and adding layers.\n",
    "#By doing this you can save a lot of computing power, time, and use a well-trained model's capability.\n",
    "#I used the VGG16 and made sure that the bulk of the model was untrainable.\n",
    "#Doing this allowed for the model to extract features from the images as it was trained to do.\n",
    "#Then I routed the features into a couple of dense layers to finalize the prediction into the value we want.\n",
    "\n",
    "transfer_model = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(120, 160, 3))\n",
    "\n",
    "for l in transfer_model.layers:\n",
    "    l.trainable = False\n",
    "    \n",
    "model = transfer_model.output\n",
    "model = tf.keras.layers.Flatten(name=\"flatten\")(model)\n",
    "model = tf.keras.layers.Dense(128, activation=\"relu\")(model)\n",
    "model = tf.keras.layers.Dense(64, activation=\"relu\")(model)\n",
    "model = tf.keras.layers.Dense(32, activation=\"relu\")(model)\n",
    "model = tf.keras.layers.Dense(1, activation=\"relu\")(model)\n",
    "\n",
    "main_model = tf.keras.Model(inputs=transfer_model.input, outputs=model)\n",
    "\n",
    "main_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feda5f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "44/44 [==============================] - 30s 651ms/step - loss: 51.7513 - val_loss: 17.5827\n",
      "Epoch 2/30\n",
      "44/44 [==============================] - 28s 632ms/step - loss: 16.1585 - val_loss: 16.1468\n",
      "Epoch 3/30\n",
      "44/44 [==============================] - 26s 594ms/step - loss: 16.1923 - val_loss: 16.0053\n",
      "Epoch 4/30\n",
      "44/44 [==============================] - 26s 596ms/step - loss: 16.0421 - val_loss: 16.2155\n",
      "Epoch 5/30\n",
      "44/44 [==============================] - 26s 591ms/step - loss: 16.2050 - val_loss: 16.0539\n",
      "Epoch 6/30\n",
      "44/44 [==============================] - 26s 597ms/step - loss: 15.7584 - val_loss: 16.4886\n",
      "Epoch 7/30\n",
      "44/44 [==============================] - 26s 595ms/step - loss: 16.4807 - val_loss: 15.9954\n",
      "Epoch 8/30\n",
      "44/44 [==============================] - 26s 595ms/step - loss: 16.0976 - val_loss: 15.9675\n",
      "Epoch 9/30\n",
      "44/44 [==============================] - 26s 600ms/step - loss: 16.1382 - val_loss: 16.2361\n",
      "Epoch 10/30\n",
      "44/44 [==============================] - 26s 603ms/step - loss: 16.2383 - val_loss: 16.0106\n",
      "Epoch 11/30\n",
      "44/44 [==============================] - 26s 587ms/step - loss: 16.1754 - val_loss: 17.6782\n",
      "Epoch 12/30\n",
      "44/44 [==============================] - 27s 610ms/step - loss: 16.0827 - val_loss: 16.1990\n",
      "Epoch 13/30\n",
      "44/44 [==============================] - 27s 612ms/step - loss: 15.6857 - val_loss: 15.8943\n",
      "Epoch 14/30\n",
      "44/44 [==============================] - 27s 612ms/step - loss: 16.0257 - val_loss: 15.9080\n",
      "Epoch 15/30\n",
      "44/44 [==============================] - 27s 610ms/step - loss: 15.7080 - val_loss: 15.9273\n",
      "Epoch 16/30\n",
      "44/44 [==============================] - 26s 593ms/step - loss: 15.8415 - val_loss: 15.8653\n",
      "Epoch 17/30\n",
      "44/44 [==============================] - 26s 595ms/step - loss: 15.9734 - val_loss: 16.0246\n",
      "Epoch 18/30\n",
      "44/44 [==============================] - 26s 599ms/step - loss: 16.2782 - val_loss: 15.9986\n",
      "Epoch 19/30\n",
      "44/44 [==============================] - 27s 618ms/step - loss: 15.7519 - val_loss: 15.9880\n",
      "Epoch 20/30\n",
      "44/44 [==============================] - 28s 636ms/step - loss: 15.6483 - val_loss: 15.9180\n",
      "Epoch 21/30\n",
      "44/44 [==============================] - 26s 602ms/step - loss: 15.6949 - val_loss: 15.9484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209b7a123a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae' \n",
    ")\n",
    "\n",
    "main_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e758dca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 8s 423ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_ages = np.squeeze(main_model.predict(test_data))\n",
    "true_ages = test_data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c36a463",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 97.9571    98.527016  97.74586   97.29035   97.08218   98.6561\n",
      "  97.76557  100.07217   96.96534   97.60577  100.23548   98.854195\n",
      "  97.90268   97.048546  98.880196  97.87058   97.017876  98.08679\n",
      "  97.53776   97.19485   97.23498   97.72741   99.928375  97.35047\n",
      "  97.42158  100.70876   98.02144   98.17393   97.93478   97.59707\n",
      " 103.647156  98.07494   97.361     98.176216  97.72613   97.028725\n",
      "  97.599785  97.99871   97.47117  101.067604  97.77884   97.66796\n",
      "  97.440605  97.33287   97.291756 102.75611  100.32215   97.93549\n",
      "  97.49672   97.60983  100.155     97.48345   97.958435  97.644325\n",
      "  97.36541   97.76757  105.054054  97.60444   99.81589   98.045235\n",
      "  97.97561   99.777176  97.69066   98.38729   98.23009   97.68894\n",
      " 100.6979    97.64396   97.999344  97.93667   99.790565  99.93709\n",
      "  98.3733    96.961494  98.02252   97.381386  97.59455   97.79033\n",
      "  98.9969    98.53669   98.31065   97.70982   97.565414  97.91305\n",
      "  97.43413   97.24263  100.77675   97.6906    99.32351   97.861336\n",
      "  97.70559   97.43479   98.03741   98.38592   97.332985  97.33808\n",
      "  98.23093   97.67979   99.04459   98.4107    98.89191   97.834755\n",
      "  97.843056 100.56204   97.988304  98.22749   97.01648   98.09449\n",
      "  97.104164  97.26545   97.09516   97.666595  97.497765  97.64033\n",
      "  99.24116   96.89128   97.62586   97.44471   97.371666 110.63805\n",
      " 103.008125  97.1264    97.545715  97.846344  98.8219    97.46993\n",
      "  96.811516  97.070175  97.74314   97.45904   97.71298   97.63678\n",
      "  97.63176   97.48291   97.79885   97.5867    97.754265  97.74683\n",
      "  98.34037   97.23661   96.948494  97.20937   98.13804   97.385185\n",
      "  96.807014 103.46147   97.64837  105.054054  97.85376   97.81028\n",
      "  97.71383   99.15617   97.73949   98.4361    97.65743   98.18293\n",
      "  97.336464  98.295845  97.8458    98.366035  98.31604   97.09727\n",
      " 101.88731   97.998604  97.25031  101.02551   97.48016   97.05805\n",
      "  97.493996  97.898476 102.23835   98.17925   97.37098   97.406105\n",
      " 100.23548   97.48032   97.72825   97.38056   98.30956   98.22114\n",
      "  97.373604  99.110016 105.540764  97.377556 100.38761   97.53058\n",
      " 100.172554  98.632805 101.47064  102.23864   97.59671   97.52439\n",
      "  97.76705   97.297295  97.786095  97.380226  97.983284  97.567345\n",
      "  97.801     97.4873    97.56635   98.32388   97.42022   99.20631\n",
      "  97.10961   97.73782   99.74894   98.18152   97.39373   97.8593\n",
      "  99.145836  97.334785  97.458305  97.54388   96.80631   97.20493\n",
      "  97.1117    97.608665  97.69885   98.12747   97.23482   93.90523\n",
      "  97.975746  97.83337   97.289246 110.63805   97.60442  109.44441\n",
      "  99.79806   97.367546  96.87458   97.176796  99.229614  97.47681\n",
      "  98.895226 100.08288   98.28809  102.25065   97.852394  98.62791\n",
      "  97.783134  97.7299    97.91516   98.02912   97.239525 100.21638\n",
      "  97.99975   97.37743   97.52634   98.58649   98.29631   97.42181\n",
      "  97.53954   97.386024 100.086945  98.066826  98.723145 111.20977\n",
      "  97.542595  97.76237  100.07617   97.64881   97.255165  97.74264\n",
      "  97.50651  100.671165  97.45542  101.0023    96.74868   97.44675\n",
      "  97.96493   97.749695  97.69584   97.87798  102.95113   97.1881\n",
      "  97.6294    98.231575  98.689026  98.021996  97.68795  105.09566\n",
      "  98.03956   97.41448   97.5702   100.71988   97.7258    97.03119\n",
      "  97.47767 ]\n",
      "[ 99 113  83  85  92  94  95  92  91  78 147 101  91  87  84 111 120  95\n",
      " 123 113 100 120 101 113  92 147  83 124 100  85 110  84  83 102  87 103\n",
      " 122 124 124 131  92 134 116 112  94  92  83  85 124 134  97 122  71  95\n",
      " 124 124 110  75  97  87 127  97  75 106 106  79 147 135  71 188  97  80\n",
      " 108 104  98  87 123 113 111  98 106  79  86 111 140 124 147  99 109 120\n",
      "  94 140  94  82  91  83 113 100 127  83  77 142  80 147 124  98  79 142\n",
      "  84 113 140 103  98 100 109  85  86 120  85 110 106  85 127 113 127  92\n",
      "  84 142  83  85 100 124  96 188  80 116  92  87  77 111  83  99  98  91\n",
      "  71  95  95 110  80  80  91  80 100 101 103  91 100  94  80 131 101  82\n",
      "  95  95 122  86 124 104 134  87  92 113  78 142 147 188 122  84 124  84\n",
      " 103 109 110  84 147 142  97 188 135  92  95  94 188 122 103 112 124  78\n",
      "  87  85 134 100 142 101 124  84  97  84 131 124 101  99 104  95 112  80\n",
      "  83  79  91  83  75 135 124 113  99 110 100 110  97  95  87 142 109 122\n",
      " 101  97  98  83 102 127 140 100 131 134  85  97  92  78  95  77 101 124\n",
      " 113  79  97 124  77 110  85  91 131  95  75  71 116 147  75 131 112 140\n",
      "  96  95  83 105 106  87  98 102 127  98  95 110  87  83  83 135 123 104\n",
      "  87]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ages)\n",
    "print(true_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea8356bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Average We Are 16.76 Off When Predicting Glucose\n"
     ]
    }
   ],
   "source": [
    "error = main_model.evaluate(test_data, verbose=0)\n",
    "print(\"On Average We Are {:.2f} Off When Predicting Glucose\".format(error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
